{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"15pZ27qInkvcPY6muDSDVMTsy0FA8vGFs","timestamp":1691163244111}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Problem 6.3: Classifying the Expansion of the Universe Using BAO Data\n","As was seen in lecture 2, the condition for which the universe's expansion is accelerating was that $w<-1/3$.\n","\n","Recall that the equation of state is given as,\n","$$\n","w = P/\\rho,\n","$$\n","where $P$ is the pressure, $\\rho$ is the density, and $w$ which is the dimensionless equation of state parameter (here, we are working in units where $c=1$). Recall further that for matter, $w_{\\rm m} = 0$ whereas for the cosmological constant, $w_\\Lambda = -1$. This implies the following relations,\n","$$\n","P_\\Lambda = -\\rho_\\Lambda, \\qquad P_{\\rm m} = 0.\n","$$\n","Since we are working in the late-universe, let us assume that *only* matter and the cosmological constants are contibuting components to any form of cosmic expansion, i.e. $\\Omega_K \\approx \\Omega_R \\approx 0$. This further implies that $\\Omega_\\Lambda = 1 - \\Omega_{\\rm m}$.\n","\n","Now, for the *total* pressure, we can write,\n","$$\n","P_{\\rm tot} = P_{\\rm m} + P_\\Lambda,\n","$$\n","however, using the relations above for the pressures, we can write\n","$$\n","P_{\\rm tot} = P_\\Lambda = -\\rho_\\Lambda,\n","$$\n","where we can finally use the relationship that $\\rho_\\Lambda = \\Omega_\\Lambda \\rho_{\\rm crit} = (1-\\Omega_{\\rm m}) \\rho_{\\rm crit}$. Therefore, we combine all of this and have,\n","$$\n","P_{\\rm tot} = -(1-\\Omega_{\\rm m}) \\rho_{\\rm crit}.\n","$$\n","Next, we wish to derive some form of relationship for $\\rho_{\\rm tot}$,\n","$$\n","\\rho_{\\rm tot} = \\rho_{\\rm m}(z) + \\rho_\\Lambda.\n","$$\n","Recalling the above relationship between $\\rho_\\Lambda$ and $\\rho_{\\rm crit}$ and again from lecture 2 that $\\rho_{\\rm m}(z) = \\Omega_{\\rm m}\\rho_{\\rm crit}(1+z)^3$, we directly get that\n","$$\n","\\rho_{\\rm tot} = \\Omega_{\\rm m}\\rho_{\\rm crit}(1+z)^3 + (1-\\Omega_{\\rm m})\\rho_{\\rm crit}.\n","$$\n","Therefore, using this, the above relationship we derived for $P_{\\rm tot}$ and the relation between these two and $w$, we can calculate $w_{\\rm tot}$ given $\\Omega_m$.\n","\n","Your goal in this Colab is to create ML models which take angular diameter distances as an input and classify whether or not that data corresponds to an accelerating ($w<-1/3$) or decelerating ($w>-1/3$) universe."],"metadata":{"id":"BFl6indYNDgT"}},{"cell_type":"markdown","source":["a.) We will prepare data from BAO, which gives us observational values for $D_A$ as a function of Redshift. We can use `numpy`'s `np.loadtxt` function to automatically load the data from a `.txt` file and store it to an array."],"metadata":{"id":"dcm-EZxTr4ek"}},{"cell_type":"code","source":["#Import libraries\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from astropy import units as u\n","from astropy.cosmology import FlatLambdaCDM  # for flat case use this"],"metadata":{"id":"tzZvWSEznDHd","executionInfo":{"status":"ok","timestamp":1691163813420,"user_tz":300,"elapsed":3178,"user":{"displayName":"Saksham Prajapati","userId":"02411259830091699842"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["#The following code allows us to download the correct data files\n","!pip install gdown"],"metadata":{"id":"Y91fnkpxsA3D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691163836835,"user_tz":300,"elapsed":21325,"user":{"displayName":"Saksham Prajapati","userId":"02411259830091699842"}},"outputId":"24759fc4-1ad8-444d-ca16-e5624a66350e"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.6.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.12.2)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.27.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.65.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.4.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2023.7.22)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"]}]},{"cell_type":"code","source":["#Load the data\n","import gdown\n","\n","# Function to convert the shared link to the correct format\n","def convert_shared_link(shared_link):\n","    return shared_link.replace(\"?usp=share_link\", \"?usp=sharing\")\n","\n","shared_link = \"https://drive.google.com/file/d/1VETN78tp7PIDpSzqUqBnSQoHArJi5P7I/view?usp=share_link\"\n","\n","# Convert the shared link to the correct format\n","shared_link_corrected = convert_shared_link(shared_link)\n","\n","# Extract the file ID from the shared link\n","file_id = shared_link_corrected.split(\"/\")[-2]\n","\n","# Destination path to save the downloaded file in the Colab environment\n","destination_path = \"/content/BAO_and_CMB_data.txt\"  # You can modify the path as per your preference\n","\n","# Download the file using gdown\n","gdown.download(f\"https://drive.google.com/uc?id={file_id}\", destination_path, quiet=False)\n","\n","# Load the data\n","data = np.loadtxt('/content/BAO_and_CMB_data.txt')\n","D_A_obs = data[:,1]\n","\n","D_A_obs = np.flip(data[:,1])\n","print(data[:,0])\n","print(D_A_obs)"],"metadata":{"id":"nSUmYGQ0sBMz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691163839690,"user_tz":300,"elapsed":1068,"user":{"displayName":"Saksham Prajapati","userId":"02411259830091699842"}},"outputId":"25603321-508d-479c-8ffa-d1f5da4f90a1"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading...\n","From: https://drive.google.com/uc?id=1VETN78tp7PIDpSzqUqBnSQoHArJi5P7I\n","To: /content/BAO_and_CMB_data.txt\n","100%|██████████| 581/581 [00:00<00:00, 1.30MB/s]"]},{"output_type":"stream","name":"stdout","text":["[1.50000000e-01 3.80185957e-01 5.10522680e-01 6.99786511e-01\n"," 8.49804744e-01 1.48071394e+00 2.29096593e+00 2.37085262e+00\n"," 1.09000000e+03]\n","[  12.54019751 1634.08006572 1688.27398489 1797.73025087 1555.79854724\n"," 1530.66619502 1308.24673246 1097.32455386  573.54982709]\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["D_A_obs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"re41R0z2ZGix","executionInfo":{"status":"ok","timestamp":1691166734888,"user_tz":300,"elapsed":125,"user":{"displayName":"Saksham Prajapati","userId":"02411259830091699842"}},"outputId":"d4227ef3-7b50-4f3d-e0f6-fe87ef954840"},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([  12.54019751, 1634.08006572, 1688.27398489, 1797.73025087,\n","       1555.79854724, 1530.66619502, 1308.24673246, 1097.32455386,\n","        573.54982709])"]},"metadata":{},"execution_count":33}]},{"cell_type":"markdown","source":["b.) Let's prepare the theory data for training and testing of our models. First, we want to calculate $w$ from the above data. We will want to do so for various values of $\\Omega_{\\rm m}$. However, the *only* value for which this matter is the one at present day, i.e. $z=0$. So for each value of $\\Omega_{\\rm m}$ we need only calculate $P_{\\rm tot}$ (why not $\\rho_{\\rm tot}$?) to calculate $w_{\\rm tot}$. Then, we will use that value to create an array of labels determining if that universe's expansion is accelerating or not. On top of that, we will also want to create an array of angular diameter distances, which should go the same as in Notebook 1 of this lecture."],"metadata":{"id":"dW9HBkO1lLku"}},{"cell_type":"code","source":["# We choose 9 points as we want to match the dimensionality of our training data to that of the BAO data\n","# z = np.linspace(0,50,9)\n","z = data[:,0]\n","\n","# Generate various values of Omega_m\n","OmM = np.arange(0.1,0.9 + 0.01,0.01)\n","OmL = 1 - OmM\n","\n","# Initialize empty list to append D_A and labels to\n","D_A = []\n","labels = []\n","\n","check_acc = []\n","\n","for i in range(len(OmM)):\n","  cosmo = FlatLambdaCDM(H0=67, Om0=OmM[i])\n","  comoving_dist = cosmo.comoving_distance(z)\n","  D_A.append(comoving_dist /(1+z))\n","  if OmL[i] > 1/3:\n","    check_acc.append(0)\n","  else: check_acc.append(1)\n"],"metadata":{"id":"lprKc1UUlLGP","executionInfo":{"status":"ok","timestamp":1691166668978,"user_tz":300,"elapsed":340,"user":{"displayName":"Saksham Prajapati","userId":"02411259830091699842"}}},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":["c.) Prepare the data for use in our ML algorithms. Make sure all labels assume values such as 0 or 1 rather than strings. Then split the data into training and testing data sets."],"metadata":{"id":"_e2FOcCqq0co"}},{"cell_type":"code","source":["# Create a dictionary to map class labels to numerical labels\n","translate_dict = {'Accelerated': 0, 'Decelerated': 1}\n","inverse_translate_dict = {v: k for k, v in translate_dict.items()}\n","\n","# Map class labels to numerical labels\n","numerical_labels = np.array([translate_dict[label] for label in labels])"],"metadata":{"id":"wZQe7TZaqzYy","executionInfo":{"status":"ok","timestamp":1691165737084,"user_tz":300,"elapsed":1,"user":{"displayName":"Saksham Prajapati","userId":"02411259830091699842"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["X = D_A\n","y = check_acc"],"metadata":{"id":"P03N34FuVa7W","executionInfo":{"status":"ok","timestamp":1691166683441,"user_tz":300,"elapsed":136,"user":{"displayName":"Saksham Prajapati","userId":"02411259830091699842"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"],"metadata":{"id":"P2D-_6NAsZuJ","executionInfo":{"status":"ok","timestamp":1691166684593,"user_tz":300,"elapsed":142,"user":{"displayName":"Saksham Prajapati","userId":"02411259830091699842"}}},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":["d.) Let's train and predict! We will use a decision tree classifier, random forest classifier, and KNN classifier."],"metadata":{"id":"ke2EUcNOsqQG"}},{"cell_type":"code","source":["from sklearn.tree import DecisionTreeClassifier\n","# DecisionTreeClassifier\n","my_tree = DecisionTreeClassifier(max_depth=4,random_state=1)\n","\n","my_tree.fit(X_train, y_train)\n","\n","# Print training and testing accuracies\n","print(\"Training Accuracy:\",my_tree.score(X_train, y_train))\n","print(\"Testing Accuracy:\",my_tree.score(X_test, y_test))"],"metadata":{"id":"DuxFoOzgs5vv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691166687089,"user_tz":300,"elapsed":130,"user":{"displayName":"Saksham Prajapati","userId":"02411259830091699842"}},"outputId":"040a01d1-fe95-4b2c-9d2e-b19b59b4fa63"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Accuracy: 1.0\n","Testing Accuracy: 0.96\n"]}]},{"cell_type":"code","source":["rslt = my_tree.predict(D_A_obs.reshape(1, -1))\n","rslt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GiGvSCtCY-Mv","executionInfo":{"status":"ok","timestamp":1691166902929,"user_tz":300,"elapsed":122,"user":{"displayName":"Saksham Prajapati","userId":"02411259830091699842"}},"outputId":"c8e9daeb-97b1-4466-bec3-611834ace031"},"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0])"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["if rslt == [0]:\n","  print(\"accelerating\")\n","else:\n","  print(\"deccelrating\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1WtOFXJ_ZxEX","executionInfo":{"status":"ok","timestamp":1691166934121,"user_tz":300,"elapsed":119,"user":{"displayName":"Saksham Prajapati","userId":"02411259830091699842"}},"outputId":"8890606d-0063-4763-8776-fbeeccce7392"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["accelerating\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score\n","# Evaluate the classifier\n","# Use model to 'predict' the test data\n","predictions = my_tree.predict(X_test)\n","# Use the accuracy metric to determine how accurate the model is\n","accuracy = accuracy_score(y_test, predictions)\n","print(\"Accuracy (DecisionTree):\", accuracy)"],"metadata":{"id":"rxNb7VLhtbgB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691167265003,"user_tz":300,"elapsed":168,"user":{"displayName":"Saksham Prajapati","userId":"02411259830091699842"}},"outputId":"154641aa-34c1-4c14-e2fc-deb57bd4dd53"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy (DecisionTree): 0.96\n"]}]},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier\n","# RandomForestClassifier\n","my_forest = RandomForestClassifier(n_estimators=4,max_depth=4,random_state=1)\n","my_forest.fit(X_train, y_train)\n","\n","# Print training and testing accuracies\n","print(\"Training Accuracy:\",my_forest.score(X_train, y_train))\n","print(\"Testing Accuracy:\",my_forest.score(X_test, y_test))"],"metadata":{"id":"VZ8wQfWnuchV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691167476111,"user_tz":300,"elapsed":141,"user":{"displayName":"Saksham Prajapati","userId":"02411259830091699842"}},"outputId":"30da55aa-a8c0-41d0-81c4-f104f70310d5"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Accuracy: 1.0\n","Testing Accuracy: 0.96\n"]}]},{"cell_type":"code","source":["# Evaluate the classifier\n","# Use model to 'predict' the test data\n","predictions = my_forest.predict(X_test)\n","# Use the accuracy metric to determine how accurate the model is\n","accuracy = accuracy_score(y_test, predictions)\n","print(\"Accuracy (DecisionTree):\", accuracy)\n"],"metadata":{"id":"VgY94YEKusf7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691167576292,"user_tz":300,"elapsed":128,"user":{"displayName":"Saksham Prajapati","userId":"02411259830091699842"}},"outputId":"50d8c8a6-1247-4293-b08a-c79209ff88e1"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy (DecisionTree): 0.96\n"]}]},{"cell_type":"code","source":["# Use model to predict acceleration from BAO data\n","f_rslt = my_forest.predict(D_A_obs.reshape(1, -1))\n","if f_rslt == [0]:\n","  print(\"accelerating\")\n","else:\n","  print(\"deccelrating\")"],"metadata":{"id":"eOLRig2ku7Fa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691167579426,"user_tz":300,"elapsed":126,"user":{"displayName":"Saksham Prajapati","userId":"02411259830091699842"}},"outputId":"b46b953e-ae5a-406f-a2be-d35318e0f037"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["accelerating\n"]}]},{"cell_type":"code","source":["from sklearn.neighbors import KNeighborsClassifier\n","# KNNClassifier\n","# Prepare KNN with k = 5\n","my_knn = KNeighborsClassifier(n_neighbors=5)\n","\n","# Fit KNN on standardized training data\n","my_knn.fit(X_train, y_train)\n","\n","# Print training and testing accuracy\n","print(\"Training Accuracy:\",my_knn.score(X_train, y_train))\n","print(\"Testing Accuracy:\",my_knn.score(X_test, y_test))"],"metadata":{"id":"XzXGXNVLvfSO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691167609043,"user_tz":300,"elapsed":124,"user":{"displayName":"Saksham Prajapati","userId":"02411259830091699842"}},"outputId":"5e635bc8-a261-424c-9632-441135157af5"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Accuracy: 1.0\n","Testing Accuracy: 0.96\n"]}]},{"cell_type":"code","source":["# Evaluate the classifier\n","# Use model to 'predict' the test data\n","predictions = my_knn.predict(X_test)\n","# Use the accuracy metric to determine how accurate the model is\n","accuracy = accuracy_score(y_test, predictions)\n","print(\"Accuracy (DecisionTree):\", accuracy)"],"metadata":{"id":"PJX8hcfevtb9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691167629509,"user_tz":300,"elapsed":124,"user":{"displayName":"Saksham Prajapati","userId":"02411259830091699842"}},"outputId":"e3dad691-0229-47d5-f604-c2ce1360e05a"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy (DecisionTree): 0.96\n"]}]},{"cell_type":"code","source":["# Use model to predict acceleration from BAO data\n","k_rslt = my_forest.predict(D_A_obs.reshape(1, -1))\n","if k_rslt == [0]:\n","  print(\"accelerating\")\n","else:\n","  print(\"deccelrating\")"],"metadata":{"id":"Pcfavivqv0XN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691167648698,"user_tz":300,"elapsed":136,"user":{"displayName":"Saksham Prajapati","userId":"02411259830091699842"}},"outputId":"5dc63914-9357-43bd-9669-ab5618d810d9"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["accelerating\n"]}]}]}